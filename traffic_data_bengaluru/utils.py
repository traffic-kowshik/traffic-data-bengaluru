"""Utility functions used throughout the project."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/utils.ipynb.

# %% auto 0
__all__ = ['logger', 'get_repo_directory', 'get_data_directory', 'get_latest_file', 'extract_file', 'extract_files',
           'get_latest_directory', 'read_file', 'append_to_file', 'extract_file_name']

# %% ../nbs/utils.ipynb 5
import tarfile
import json
import pandas as pd
from fastcore.all import Path

from nbdev.config import get_config
from pathlib import Path
from io import TextIOWrapper

import warnings
warnings.filterwarnings("ignore")

# %% ../nbs/utils.ipynb 6
import logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s"
)
logger = logging.getLogger(__name__)

# %% ../nbs/utils.ipynb 8
def get_repo_directory():
    cfg = get_config()
    project_root = Path(cfg.nbs_path).parent
    return project_root

# %% ../nbs/utils.ipynb 11
def get_data_directory():
    data_directory = get_repo_directory() / 'data'
    data_directory.mkdir(parents=True, exist_ok=True)
    return data_directory

# %% ../nbs/utils.ipynb 14
def get_latest_file(directory: Path):
    "Return the latest file, sorting by name for a given directory. Only returns files, not directories."
    files = (
        directory
        .ls()
        .filter(lambda f: not f.name.startswith('.') and f.is_file())
        .sorted(key=lambda f: f.name)
    )
    if len(files) > 0:
        return files[-1]

# %% ../nbs/utils.ipynb 17
def extract_file(filepath: Path):

    if filepath.suffix != ".gz":
        return filepath

    extract_dir = filepath.parent
    extracted_files = []

    with tarfile.open(filepath, "r:gz") as tar:
        for member in tar.getmembers():
            if Path(member.name).name.startswith("._"):
                continue
            tar.extract(member, path=extract_dir)
            extracted_files.append(extract_dir / member.name)

    for du_file in extract_dir.glob("._*"):
        du_file.unlink()

    if len(extracted_files) != 1:
        assert False, f"Expected 1 file, got {len(extracted_files)}"
    return extracted_files[0]

# %% ../nbs/utils.ipynb 20
def extract_files(filepath: Path):
    
    # When the filepath is not compressed, return only files in the directory.
    if filepath.suffix != ".gz":
        return [p for p in filepath.ls() if p.is_file()]

    extract_dir = filepath.parent
    extracted_files = []

    with tarfile.open(filepath, "r:gz") as tar:
        for member in tar.getmembers():
            if not member.isfile():  # skip directories
                continue
            if Path(member.name).name.startswith("._"):  # skip macOS junk
                continue
            tar.extract(member, path=extract_dir)
            extracted_files.append(extract_dir / member.name)

    # Remove duplicate macOS junk files if any slipped through
    for du_file in extract_dir.glob("._*"):
        du_file.unlink()

    return extracted_files

# %% ../nbs/utils.ipynb 24
def get_latest_directory(directory: Path):
    "Return the latest subdirectory, sorting by name for a given directory. Only returns directories, not files."
    directories = (
        directory
        .ls()
        .filter(lambda f: not f.name.startswith('.') and f.is_dir())
        .sorted(key=lambda f: f.name)
    )
    
    if len(directories):
        latest = directories[-1]
        return latest

# %% ../nbs/utils.ipynb 27
def read_file(filepath: Path, format: str = 'json'):
    "Read a file in either JSON or CSV format and return its contents."
    with open(filepath) as f:
        if format == 'json':
            return json.load(f)
        elif format == 'csv':
            return pd.read_csv(f)
        else:
            raise ValueError(f"Unsupported format: {format}")

# %% ../nbs/utils.ipynb 30
def append_to_file(filepath: Path, record: dict):
    filepath.parent.mkdir(parents=True, exist_ok=True)
    record_str = json.dumps(record)

    existing_lines = set()
    if filepath.exists():
        with open(filepath, 'r', encoding='utf-8') as f:
            existing_lines = set(line.strip() for line in f)

    if record_str not in existing_lines:
        with open(filepath, 'a', encoding='utf-8') as f:
            f.write(record_str + "\n")
        logging.info(f"Record added.")
    else:
        logging.info("Record already exists.")


# %% ../nbs/utils.ipynb 33
def extract_file_name(path: Path) -> str:
    if not path.suffix:
        return path.name
    return extract_file_name(path.with_suffix(''))

